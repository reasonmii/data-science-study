{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KJT5kqyZGe1p"
   },
   "source": [
    "# Fashion Mnist DNN Tutorial [CNN & Multi-layer Perceptron (MLP)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NzHP2rndF-0G"
   },
   "source": [
    "## 외부 파일 가져오기 & requirements 설치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Mi95dewjGeW_"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount(\"/content/drive\")\n",
    "import os\n",
    "import sys\n",
    "from datetime import datetime\n",
    "\n",
    "drive_project_root = \"/content/drive/MyDrive/#fastcampus\"\n",
    "sys.path.append(drive_project_root)\n",
    "!pip install -r \"/content/drive/MyDrive/#fastcampus/requirements.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gFlvgHkj2wzZ"
   },
   "outputs": [],
   "source": [
    "gpu_info = !nvidia-smi\n",
    "gpu_info = \"\\n\".join(gpu_info)\n",
    "print(gpu_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_9djS-LtvmwC"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YD7vyST9GdHv"
   },
   "outputs": [],
   "source": [
    "from abc import abstractmethod\n",
    "from typing import Optional\n",
    "from typing import Dict\n",
    "from typing import List\n",
    "from typing import Union\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from omegaconf import OmegaConf\n",
    "from omegaconf import DictConfig\n",
    "import hydra\n",
    "from hydra.core.config_store import ConfigStore\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "from torch_optimizer import RAdam\n",
    "from torch_optimizer import AdamP\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.utils.data import random_split\n",
    "from torchvision.datasets import FashionMNIST\n",
    "from torchvision import transforms\n",
    "import wandb\n",
    "\n",
    "from efficientnet_pytorch import EfficientNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QX3soatAMk5B"
   },
   "outputs": [],
   "source": [
    "from data_utils import dataset_split\n",
    "from config_utils import flatten_dict\n",
    "from config_utils import register_config\n",
    "from config_utils import configure_optimizers_from_cfg\n",
    "from config_utils import get_loggers\n",
    "from config_utils import get_callbacks\n",
    "from custom_math import softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lwd5nW_3N37z"
   },
   "source": [
    "## 모델 (Multi-layer Perceptron) (MLP) ! 정의\n",
    "## 모델 MLPWithDropout 정의\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vNBF3WY_Z0rY"
   },
   "outputs": [],
   "source": [
    "class BaseLightningModule(pl.LightningModule):\n",
    "    def __init__(self, cfg: DictConfig):\n",
    "        pl.LightningModule.__init__(self)\n",
    "        self.cfg = cfg\n",
    "        self.loss_function = nn.CrossEntropyLoss()\n",
    "    \n",
    "    @abstractmethod\n",
    "    def forward(self, x):\n",
    "        raise NotImplementedError()\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        self._optimizers, self._schedulers = configure_optimizers_from_cfg(self.cfg, self)\n",
    "        return self._optimizers, self._schedulers\n",
    "    \n",
    "    def _forward(self, images, labels, mode: str):\n",
    "\n",
    "        assert mode in [\"train\", \"val\", \"test\"]\n",
    "\n",
    "        # get predictions\n",
    "        outputs = model(images)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "\n",
    "        # get loss (Loss 계산)\n",
    "        loss = self.loss_function(outputs, labels)\n",
    "        corrects = torch.sum(preds == labels.data)\n",
    "        acc = corrects / len(outputs)\n",
    "\n",
    "        return {\n",
    "            f\"{mode}_loss\": loss,\n",
    "            f\"{mode}_acc\": acc,\n",
    "        }, {\n",
    "            f\"{mode}_outputs\": outputs,\n",
    "            f\"{mode}_preds\": preds,\n",
    "            f\"{mode}_images\": images,\n",
    "            f\"{mode}_labels\": labels,\n",
    "            f\"{mode}_corrects\": corrects,\n",
    "        }\n",
    "\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        images, labels = batch\n",
    "        logs, _ = self._forward(images, labels, mode=\"train\")\n",
    "        self.log_dict(logs)\n",
    "        logs[\"loss\"] = logs[\"train_loss\"]\n",
    "        return logs\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        images, labels = batch\n",
    "        logs, _ = self._forward(images, labels, mode=\"val\")\n",
    "        self.log_dict(logs)\n",
    "        logs[\"loss\"] = logs[\"val_loss\"]\n",
    "        return logs\n",
    "    \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        images, labels = batch\n",
    "        logs, logs_detail = self._forward(images, labels, mode=\"test\")\n",
    "        self.log_dict(logs)\n",
    "        logs[\"loss\"] = logs[\"test_loss\"]\n",
    "        logs.update(logs_detail)\n",
    "        return logs\n",
    "    \n",
    "    def test_epoch_end(self, step_end_outputs):\n",
    "        \n",
    "        model_outputs = torch.cat([o[\"test_outputs\"] for o in step_end_outputs]).detach().cpu().numpy()\n",
    "        labels = torch.cat([o[\"test_labels\"] for o in step_end_outputs]).detach().cpu().numpy()\n",
    "        preds = torch.cat([o[\"test_preds\"] for o in step_end_outputs]).detach().cpu().numpy()\n",
    "        corrects = torch.cat([o[\"test_corrects\"] for o in step_end_outputs]).detach().cpu().numpy()\n",
    "        losses = torch.cat([o[\"test_loss\"] for o in step_end_outputs]).detach().cpu().numpy()\n",
    "\n",
    "        final_outs = softmax(model_outputs, axis=1)\n",
    "\n",
    "        fpr = {}\n",
    "        tpr = {}\n",
    "        thresh = {}\n",
    "        n_class = self.cfg.data.n_class\n",
    "\n",
    "        for i in range(n_class):\n",
    "            fpr[i], tpr[i], thresh[i] = roc_curve(test_labels_list, model_outputs[:, i], pos_label=i)\n",
    "\n",
    "        # plot.\n",
    "        for i in range(n_class):\n",
    "            plt.plot(fpr[i], tpr[i], linestyle=\"--\", label=f\"Class {i} vs Rest\")\n",
    "        plt.title(\"Multi-class ROC Curve\")\n",
    "        plt.xlabel(\"False Positive Rate\")\n",
    "        plt.ylabel(\"True Positive Rate\")\n",
    "        plt.legend(loc=\"best\")\n",
    "        # plt.show()\n",
    "\n",
    "        auc_score = roc_auc_score(\n",
    "            test_labels_list, test_outputs_list, multi_class=\"ovo\", average=\"macro\"\n",
    "        )\n",
    "\n",
    "        acc = corrects / len(corrects)\n",
    "        mean_loss = np.mean(losses)\n",
    "\n",
    "        return {\n",
    "            \"test_auc_score\": auc_score,\n",
    "            \"test_accuracy\": acc,\n",
    "            \"test_loss\": mean_loss\n",
    "        }\n",
    "    \n",
    "# TODO: add below things in the configs.\n",
    "# cfg.data.n_class\n",
    "# cfg.opt.lr_schedulers\n",
    "# cfg.opt.optimizers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-O--VMLMN04F"
   },
   "outputs": [],
   "source": [
    "# Define Model.\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, in_dim: int, h1_dim: int, h2_dim: int, out_dim: int):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(in_dim, h1_dim)\n",
    "        self.linear2 = nn.Linear(h1_dim, h2_dim)\n",
    "        self.linear3 = nn.Linear(h2_dim, out_dim)\n",
    "        self.relu = F.relu\n",
    "        pass\n",
    "    \n",
    "    def forward(self, input):\n",
    "        x = torch.flatten(input, start_dim=1)\n",
    "        x = self.relu(self.linear1(x))\n",
    "        x = self.relu(self.linear2(x))\n",
    "        out = self.linear3(x)\n",
    "        # out = F.softmax(out)\n",
    "        return out\n",
    "\n",
    "class PLMLP(BaseLightningModule):\n",
    "    def __init__(self, cfg: DictConfig):\n",
    "        BaseLightningModule.__init__(self, cfg=cfg)\n",
    "        self.linear1 = nn.Linear(cfg.model.in_dim, cfg.model.h1_dim)\n",
    "        self.linear2 = nn.Linear(cfg.model.h1_dim, cfg.model.h2_dim)\n",
    "        self.linear3 = nn.Linear(cfg.model.h2_dim, cfg.model.out_dim)\n",
    "        self.relu = F.relu\n",
    "        pass\n",
    "    \n",
    "    def forward(self, input):\n",
    "        x = torch.flatten(input, start_dim=1)\n",
    "        x = self.relu(self.linear1(x))\n",
    "        x = self.relu(self.linear2(x))\n",
    "        out = self.linear3(x)\n",
    "        # out = F.softmax(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class MLPWithDropout(MLP):\n",
    "    def __init__(self, in_dim: int, h1_dim: int, h2_dim: int, out_dim: int, dropout_prob: float):\n",
    "        super().__init__(in_dim, h1_dim, h2_dim, out_dim)\n",
    "        self.dropout1 = nn.Dropout(dropout_prob)\n",
    "        self.dropout2 = nn.Dropout(dropout_prob)\n",
    "    \n",
    "    def forward(self, input):\n",
    "        x = torch.flatten(input, start_dim=1)\n",
    "        x = self.relu(self.linear1(x))\n",
    "        x = self.dropout1(x)\n",
    "        x = self.relu(self.linear2(x))\n",
    "        x = self.dropout2(x)\n",
    "        out = self.linear3(x)\n",
    "        # out = F.softmax(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "42in1xpAqQDY"
   },
   "source": [
    "## CNN 모델 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dCEx_VgEqTiB"
   },
   "outputs": [],
   "source": [
    "_cnn_cfg_dict: dict = {\n",
    "    \"layer_1\": {\n",
    "        \"conv2d_in_channels\": 1,\n",
    "        \"conv2d_out_channels\": 32,\n",
    "        \"conv2d_kernel_size\": 3,\n",
    "        \"conv2d_padding\": 1,\n",
    "        \"maxpool2d_kernel_size\": 2,\n",
    "        \"maxpool2d_stride\": 2,\n",
    "    },\n",
    "    \"layer_2\": {\n",
    "        \"conv2d_in_channels\": 32,\n",
    "        \"conv2d_out_channels\": 64,\n",
    "        \"conv2d_kernel_size\": 3,\n",
    "        \"conv2d_padding\": 0,\n",
    "        \"maxpool2d_kernel_size\": 2,\n",
    "        \"maxpool2d_stride\": 1,\n",
    "    },\n",
    "    \"fc_1\": {\n",
    "        \"in_features\": 2304, #  수정 필요!\n",
    "        \"out_features\": 512,\n",
    "    },\n",
    "    \"fc_2\": {\n",
    "        \"in_features\": 512,\n",
    "        \"out_features\": 128,        \n",
    "    },\n",
    "    \"fc_3\": {\n",
    "        \"in_features\": 128,\n",
    "        \"out_features\": 10,\n",
    "    },\n",
    "    \"dropout_prob\": 0.25,\n",
    "}\n",
    "_cnn_cfg = OmegaConf.create(_cnn_cfg_dict)\n",
    "print(OmegaConf.to_yaml(_cnn_cfg))\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, cfg: DictConfig = _cnn_cfg):\n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=cfg.layer_1.conv2d_in_channels,\n",
    "                out_channels=cfg.layer_1.conv2d_out_channels,\n",
    "                kernel_size=cfg.layer_1.conv2d_kernel_size,\n",
    "                padding=cfg.layer_1.conv2d_padding\n",
    "            ),\n",
    "            nn.BatchNorm2d(cfg.layer_1.conv2d_out_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(\n",
    "                kernel_size=cfg.layer_1.maxpool2d_kernel_size,\n",
    "                stride=cfg.layer_1.maxpool2d_kernel_size\n",
    "            )\n",
    "        )\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=cfg.layer_2.conv2d_in_channels,\n",
    "                out_channels=cfg.layer_2.conv2d_out_channels,\n",
    "                kernel_size=cfg.layer_2.conv2d_kernel_size,\n",
    "                padding=cfg.layer_2.conv2d_padding\n",
    "            ),\n",
    "            nn.BatchNorm2d(cfg.layer_2.conv2d_out_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(\n",
    "                kernel_size=cfg.layer_2.maxpool2d_kernel_size,\n",
    "                stride=cfg.layer_2.maxpool2d_kernel_size\n",
    "            )\n",
    "        )\n",
    "        self.fc1 = nn.Linear(\n",
    "            in_features=cfg.fc_1.in_features,\n",
    "            out_features=cfg.fc_1.out_features,\n",
    "        )\n",
    "        self.fc2 = nn.Linear(\n",
    "            in_features=cfg.fc_2.in_features,\n",
    "            out_features=cfg.fc_2.out_features,\n",
    "        )\n",
    "        self.fc3 = nn.Linear(\n",
    "            in_features=cfg.fc_3.in_features,\n",
    "            out_features=cfg.fc_3.out_features,\n",
    "        )\n",
    "        self.dropout = nn.Dropout2d(cfg.dropout_prob)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.fc1(out)\n",
    "        out = self.dropout(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.fc3(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HVNk_qol3eCz"
   },
   "outputs": [],
   "source": [
    "_efficient_finetune_cfg_dict: dict = {\n",
    "    \"efficient_net_model_name\": \"efficientnet-b1\",\n",
    "    \"num_classes\": 10\n",
    "}\n",
    "_efficient_finetune_cfg_cfg = OmegaConf.create(_efficient_finetune_cfg_dict)\n",
    "print(OmegaConf.to_yaml(_efficient_finetune_cfg_cfg))\n",
    "\n",
    "class EfficientNetFinetune(nn.Module):\n",
    "    def __init__(self, cfg: DictConfig = _efficient_finetune_cfg_cfg):\n",
    "        super().__init__()\n",
    "        self.efficientnet = EfficientNet.from_pretrained(\n",
    "            cfg.efficient_net_model_name,\n",
    "            cfg.num_classes\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.efficientnet(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OMzKfPjHjQLb"
   },
   "outputs": [],
   "source": [
    "# transform = transforms.Compose(\n",
    "#     [\n",
    "#         transforms.Resize(224),\n",
    "#         transforms.ToTensor(),\n",
    "#         transforms.Lambda(lambda x: x.repeat(3, 1, 1)),\n",
    "#         transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "#     ]\n",
    "# )\n",
    "\n",
    "\n",
    "\n",
    "# data configs\n",
    "data_fashion_mnist_cfg = {\n",
    "    \"name\": \"fashion_mnist\",\n",
    "    \"data_root\": os.path.join(os.getcwd(), \"data\"),\n",
    "    \"W\": 28,\n",
    "    \"H\": 28,\n",
    "    \"C\": 1,\n",
    "    \"n_class\": 10,\n",
    "}\n",
    "\n",
    "# model configs \n",
    "model_mnist_mlp_cfg = {\n",
    "    \"name\": \"MLP\",\n",
    "    \"in_dim\": 28*28,\n",
    "    \"h1_dim\": 128,\n",
    "    \"h2_dim\": 64,\n",
    "    \"out_dim\": 10,\n",
    "    \"feature\": {\n",
    "        \"normalize\": {\n",
    "            \"mean\": [0.5],\n",
    "            \"std\": [0.5],\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# optimizer configs\n",
    "opt_cfg = {\n",
    "    \"optimizers\": [\n",
    "        {\n",
    "            \"name\": \"RAdam\",\n",
    "            \"kwargs\": {\n",
    "                \"lr\": 1e-3,\n",
    "                \"betas\": (0.9, 0.999),\n",
    "                \"eps\": 1e-8,\n",
    "                \"weight_decay\": 0,\n",
    "            },\n",
    "        }\n",
    "    ],\n",
    "    \"lr_schedulers\": [\n",
    "        {\n",
    "            \"name\": None,\n",
    "            \"kwargs\": {}\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "_merged_cfg_presets = {\n",
    "    \"mlp_fashion_mnist\": {\n",
    "        \"data\": data_fashion_mnist_cfg,\n",
    "        \"model\": model_mnist_mlp_cfg,\n",
    "        \"opt\": opt_cfg, \n",
    "    },\n",
    "}\n",
    "\n",
    "### hydra composition ###\n",
    "# clear hydra instance first\n",
    "hydra.core.global_hydra.GlobalHydra.instance().clear()\n",
    "\n",
    "# register preset configs\n",
    "register_config(_merged_cfg_presets)\n",
    "\n",
    "\n",
    "# initializing\n",
    "hydra.initialize(config_path=None)\n",
    "\n",
    "# compose\n",
    "cfg = hydra.compose(\"mlp_fashion_mnist\")\n",
    "\n",
    "###\n",
    "\n",
    "# override some cfg \n",
    "run_name = f\"{datetime.now().isoformat(timespec='seconds')}-{cfg.model.name}-{cfg.data.name}\"\n",
    "\n",
    "\n",
    "## Define train configs\n",
    "project_root_dir = os.path.join(\n",
    "    drive_project_root, \"runs\", \"dnn-tutorial-fashion-mnist-runs\"\n",
    ")\n",
    "save_dir = os.path.join(project_root_dir, run_name)\n",
    "run_root_dir = os.path.join(project_root_dir, run_name)\n",
    "\n",
    "# train configs\n",
    "train_cfg = {\n",
    "    \"train_batch_size\": 128,\n",
    "    \"val_batch_size\": 32,\n",
    "    \"test_batch_size\": 32,\n",
    "    \"train_val_split\": [0.9, 0.1],\n",
    "    \"run_root_dir\": run_root_dir,\n",
    "    \"trainer_kwargs\": {\n",
    "        \"accelerator\": \"dp\",\n",
    "        \"gpus\": \"0\",\n",
    "        \"max_epochs\": 50,\n",
    "        \"val_check_interval\": 1.0,\n",
    "        \"log_every_n_steps\": 100,\n",
    "        \"flush_logs_every_n_steps\": 100,\n",
    "    }\n",
    "}\n",
    "\n",
    "# logger configs \n",
    "log_cfg = {\n",
    "    \"loggers\": {\n",
    "        \"WandbLogger\": {\n",
    "            \"project\": \"fastcampus_fashion_mnist_tutorials\",\n",
    "            \"name\": run_name,\n",
    "            \"tags\": [\"fastcampus_fashion_mnist_tutorials\"],\n",
    "            \"save_dir\": run_root_dir,\n",
    "        },\n",
    "        \"TensorBoardLogger\": {\n",
    "            \"save_dir\": project_root_dir,\n",
    "            \"name\": run_name,\n",
    "        }\n",
    "    },\n",
    "    \"callbacks\": {\n",
    "        \"ModelCheckpoint\": {\n",
    "            \"save_top_k\": 3,\n",
    "            \"monitor\": \"val_loss\",\n",
    "            \"mode\": \"min\",\n",
    "            \"verbose\": True,\n",
    "            \"dirpath\": os.path.join(run_root_dir, \"weights\"),\n",
    "            \"filename\": \"{epoch}-{val_loss:.3f}-{val_acc:.3f}\"\n",
    "        },\n",
    "        \"EarlyStopping\": {\n",
    "            \"monitor\": \"val_loss\",\n",
    "            \"mode\": \"min\",\n",
    "            \"patience\": 3,\n",
    "            \"verbose\": True,\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# unlock config & set train, log confg\n",
    "OmegaConf.set_struct(cfg, False)\n",
    "cfg.train = train_cfg\n",
    "cfg.log = log_cfg\n",
    "\n",
    "# lock config\n",
    "OmegaConf.set_struct(cfg, True)\n",
    "print(OmegaConf.to_yaml(cfg))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5NOm5_pPsQwx"
   },
   "outputs": [],
   "source": [
    "data_root = cfg.data.data_root\n",
    "\n",
    "# 전처리 부분 (preprocessing) & 데이터 셋 정의.\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(\n",
    "            cfg.model.feature.normalize.mean,\n",
    "            cfg.model.feature.normalize.std,\n",
    "        ), # mean, # std\n",
    "    ]\n",
    ")\n",
    "\n",
    "# transform = transforms.Compose(\n",
    "#     [\n",
    "#         transforms.Resize(cfg.data.W*cfg.data.H*cfg.data.C),\n",
    "#         transforms.ToTensor(),\n",
    "#         transforms.Lambda(lambda x: x.repeat(3, 1, 1)),\n",
    "#         transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "#     ]\n",
    "# )\n",
    "\n",
    "fashion_mnist_dataset = FashionMNIST(data_root, download=True, train=True, transform=transform)\n",
    "test_dataset = FashionMNIST(data_root, download=True, train=False, transform=transform)\n",
    "\n",
    "datasets = dataset_split(fashion_mnist_dataset, split=cfg.train.train_val_split)\n",
    "\n",
    "train_dataset = datasets[\"train\"]\n",
    "val_dataset = datasets[\"val\"]\n",
    "\n",
    "train_batch_size = cfg.train.train_batch_size\n",
    "val_batch_size = cfg.train.val_batch_size\n",
    "test_batch_size = cfg.train.test_batch_size\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "    train_dataset, batch_size=train_batch_size, shuffle=True, num_workers=0\n",
    ")\n",
    "val_dataloader = torch.utils.data.DataLoader(\n",
    "    val_dataset, batch_size=val_batch_size, shuffle=False, num_workers=0\n",
    ")\n",
    "test_dataloader = torch.utils.data.DataLoader(\n",
    "    test_dataset, batch_size=val_batch_size, shuffle=False, num_workers=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b8tljBSaQBZB"
   },
   "source": [
    "## 모델 선언 및 손실 함수, 최적화(Optimizer) 정의, Tensorboard Logger 정의 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z8p_hsjsO-on"
   },
   "outputs": [],
   "source": [
    "# model define\n",
    "\n",
    "def get_pl_model(cfg: DictConfig, checkpoint_path: Optional[str] = None):\n",
    "\n",
    "    if cfg.model.name == \"MLP\":\n",
    "        model = PLMLP(cfg)\n",
    "    else:\n",
    "        raise NotImplementedError()\n",
    "    \n",
    "    if checkpoint_path is not None:\n",
    "        model = model.load_from_checkpoint(cfg=cfg, checkpoint_path=checkpoint_path)\n",
    "    return model\n",
    "\n",
    "model = get_pl_model(cfg)\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_nTzE40svgsB"
   },
   "outputs": [],
   "source": [
    "logger = get_loggers(cfg)\n",
    "callbacks = get_callbacks(cfg)\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    callbacks=callbacks,\n",
    "    logger=logger,\n",
    "    default_root_dir=cfg.train.run_root_dir,\n",
    "    num_sanity_val_steps=2,\n",
    "    **cfg.train.trainer_kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b93vvDdCv9LZ"
   },
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir /content/drive/MyDrive/\\#fastcampus/runs/dnn-tutorial-fashion-mnist-runs/\n",
    "\n",
    "trainer.fit(model, train_dataloader, val_dataloader)\n",
    "# trainer.test(model, test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oq-XpcGXQu1v"
   },
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir /content/drive/MyDrive/\\#fastcampus/runs/dnn-tutorial-fashion-mnist-runs/\n",
    "\n",
    "# define EarlyStopping.\n",
    "early_stopper = EarlyStopping(\n",
    "    patience=3, verbose=True, path=os.path.join(log_model_path, \"model.ckpt\")\n",
    ")\n",
    "\n",
    "# do train with validation.\n",
    "train_step = 0\n",
    "for epoch in range(1, max_epoch+1):\n",
    "    # valid step\n",
    "    with torch.no_grad():\n",
    "        val_loss = 0.0\n",
    "        val_corrects = 0\n",
    "        model.eval()\n",
    "\n",
    "        for val_batch_idx, (val_images, val_labels) in enumerate(\n",
    "            tqdm(val_dataloader, position=0, leave=True, desc=\"validation\")\n",
    "        ):\n",
    "            if gpu is not None:\n",
    "                val_images = val_images.cuda(gpu, non_blocking=True)\n",
    "                val_labels = val_labels.cuda(gpu, non_blocking=True)\n",
    "            # forward\n",
    "            val_outputs = model(val_images)\n",
    "            _, val_preds = torch.max(val_outputs, 1)\n",
    "            \n",
    "            # loss & acc\n",
    "            val_loss += loss_function(val_outputs, val_labels) / val_outputs.shape[0]\n",
    "            val_corrects += torch.sum(val_preds == val_labels.data) / val_outputs.shape[0]\n",
    "    \n",
    "    # valid step logging\n",
    "    val_epoch_loss = val_loss / len(val_dataloader)\n",
    "    val_epoch_acc = val_corrects / len(val_dataloader)\n",
    "    \n",
    "    print(\n",
    "        f\"{epoch} epoch, {train_step} step: val_loss: {val_epoch_loss}, val_acc: {val_epoch_acc}\"\n",
    "    )\n",
    "\n",
    "    # tensorboard log\n",
    "    writer.add_scalar(\"Loss/val\", val_epoch_loss, train_step)\n",
    "    writer.add_scalar(\"Acc/val\", val_epoch_acc, train_step)\n",
    "    writer.add_images(\"Images/val\", val_images, train_step)\n",
    "\n",
    "    # wandb log\n",
    "    wandb.log({\n",
    "        \"Loss/val\": val_epoch_loss,\n",
    "        \"Acc/val\": val_epoch_acc,\n",
    "        \"Images/val\": wandb.Image(val_images),\n",
    "        \"Outputs/val\": wandb.Histogram(val_outputs.detach().cpu().numpy()),\n",
    "        \"Preds/val\": wandb.Histogram(val_preds.detach().cpu().numpy()),\n",
    "        \"Labels/val\": wandb.Histogram(val_labels.data.detach().cpu().numpy()),\n",
    "    }, step=train_step)\n",
    "\n",
    "    # check model early stopping point & save model if the model reached the best performance.\n",
    "    early_stopper(val_epoch_loss, model)\n",
    "    if early_stopper.early_stop:\n",
    "        break\n",
    "    \n",
    "    # train step\n",
    "    current_loss = 0\n",
    "    current_corrects = 0\n",
    "    model.train()\n",
    "\n",
    "    for batch_idx, (images, labels) in enumerate(\n",
    "         tqdm(train_dataloader, position=0, leave=True, desc=\"training\")\n",
    "    ):\n",
    "        if gpu is not None:\n",
    "            images = images.cuda(gpu)\n",
    "            labels = labels.cuda(gpu)\n",
    "\n",
    "        current_loss = 0.0\n",
    "        current_corrects = 0\n",
    "\n",
    "        # Forward\n",
    "        # get predictions\n",
    "        outputs = model(images)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        \n",
    "        # get loss (Loss 계산)\n",
    "        loss = loss_function(outputs, labels)\n",
    "\n",
    "        # Backpropagation\n",
    "        # optimizer 초기화 (zero화)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Perform backward pass\n",
    "        loss.backward()\n",
    "\n",
    "        # Perform Optimization\n",
    "        optimizer.step()\n",
    "\n",
    "        # Perform LR scheduler Work\n",
    "        if scheduler is not None:\n",
    "            scheduler.step()\n",
    "        \n",
    "        current_loss = 0.0\n",
    "        current_corrects = 0\n",
    "\n",
    "        # Forward\n",
    "        # get predictions\n",
    "        outputs = model(images)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        \n",
    "        # get loss (Loss 계산)\n",
    "        loss = loss_function(outputs, labels)\n",
    "\n",
    "        current_loss += loss.item()\n",
    "        current_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "        if train_step % log_interval == 0:\n",
    "            train_loss = current_loss / log_interval\n",
    "            train_acc = current_corrects / log_interval\n",
    "\n",
    "            print(\n",
    "                f\"{train_step}: train_loss: {train_loss}, train_acc: {train_acc}\"\n",
    "            )\n",
    "            \n",
    "            cur_lr = optimizer.param_groups[0][\"lr\"] if scheduler is None else scheduler.get_last_lr()[0]                \n",
    "\n",
    "            # tensorboard log\n",
    "            writer.add_scalar(\"Loss/train\", train_loss, train_step)\n",
    "            writer.add_scalar(\"Acc/train\", train_acc, train_step)\n",
    "            writer.add_images(\"Images/train\", images, train_step)\n",
    "            writer.add_scalar(\"Learning Rate\", cur_lr, train_step)\n",
    "            writer.add_graph(model, images)\n",
    "\n",
    "            # wandb log\n",
    "            wandb.log({\n",
    "                \"Loss/train\": train_loss,\n",
    "                \"Acc/train\": train_acc,\n",
    "                \"Images/train\": wandb.Image(images),\n",
    "                \"Outputs/train\": wandb.Histogram(outputs.detach().cpu().numpy()),\n",
    "                \"Preds/train\": wandb.Histogram(preds.detach().cpu().numpy()),\n",
    "                \"Labels/train\": wandb.Histogram(labels.data.detach().cpu().numpy()),\n",
    "                \"Learning Rate\": cur_lr,\n",
    "            }, step=train_step)\n",
    "\n",
    "            current_loss = 0\n",
    "            current_corrects = 0\n",
    "\n",
    "        train_step += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ymnDN1VkYOvt"
   },
   "outputs": [],
   "source": [
    "# load model\n",
    "loaded_model = torch.load(os.path.join(log_model_path, \"val_loss-0.02419060841202736-model.ckpt\"))\n",
    "loaded_model.cpu()\n",
    "loaded_model.eval()\n",
    "print(loaded_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_UoTf2ztY7nT"
   },
   "outputs": [],
   "source": [
    "test_batch_size = 100\n",
    "test_dataset = FashionMNIST(data_root, download=True, train=False, transform=transforms.ToTensor())\n",
    "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=test_batch_size, shuffle=False, num_workers=1)\n",
    "\n",
    "test_labels_list = []\n",
    "test_preds_list = []\n",
    "test_outputs_list = []\n",
    "for i, (test_images, test_labels) in enumerate(tqdm(test_dataloader, position=0, leave=True, desc=\"testing\")):\n",
    "    # forward\n",
    "    test_outputs = loaded_model(test_images)\n",
    "    _, test_preds = torch.max(test_outputs, 1)\n",
    "\n",
    "    final_outs = softmax(test_outputs.detach().numpy(), axis=1)\n",
    "    test_outputs_list.extend(final_outs)\n",
    "    test_preds_list.extend(test_preds.detach().numpy())\n",
    "    test_labels_list.extend(test_labels.detach().numpy())\n",
    "\n",
    "test_preds_list = np.array(test_preds_list)\n",
    "test_labels_list = np.array(test_labels_list)\n",
    "\n",
    "print(f\"\\nacc: {np.mean(test_preds_list == test_labels_list)*100}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M0a4PPefaRfH"
   },
   "outputs": [],
   "source": [
    "# ROC Curve\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "\n",
    "final_outs = softmax(test_outputs.detach().numpy(), axis=1)\n",
    "fpr = {}\n",
    "tpr = {}\n",
    "thresh = {}\n",
    "n_class = 10\n",
    "\n",
    "for i in range(n_class):\n",
    "    fpr[i], tpr[i], thresh[i] = roc_curve(test_labels_list, np.array(test_outputs_list)[:, i], pos_label=i)\n",
    "\n",
    "# plot.\n",
    "for i in range(n_class):\n",
    "    plt.plot(fpr[i], tpr[i], linestyle=\"--\", label=f\"Class {i} vs Rest\")\n",
    "plt.title(\"Multi-class ROC Curve\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()\n",
    "\n",
    "print(\"auc_score\", roc_auc_score(test_labels_list, test_outputs_list, multi_class=\"ovo\", average=\"macro\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Dm5jZ7urbMAO"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPRvzFH1Um/XTl3NOQYNHaj",
   "collapsed_sections": [],
   "mount_file_id": "1gNh-HsjMOM_aMXda7EfQdjZjqAA3DNqt",
   "name": "05-3. Pytorch-lightning & Hydra, CNN",
   "private_outputs": true,
   "provenance": [
    {
     "file_id": "1erxCNSOQW7VIAG2BHeIn3JT8c7meNa7T",
     "timestamp": 1628854419947
    },
    {
     "file_id": "1Z45RhZD6DFfZgDsoSGZhYKoAhgf4szLf",
     "timestamp": 1628427684925
    },
    {
     "file_id": "1vOwqGgv4OKk-1vYWcH8uFpvoIooaUeTj",
     "timestamp": 1628424146619
    },
    {
     "file_id": "1n37-PsBNU1tEXNwUvWohvHVJD81-C8m2",
     "timestamp": 1627212638626
    },
    {
     "file_id": "1gNh-HsjMOM_aMXda7EfQdjZjqAA3DNqt",
     "timestamp": 1626696451891
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
