{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"03. MLP + basic regularizers (dropout, early stopping).ipynb","private_outputs":true,"provenance":[{"file_id":"1gNh-HsjMOM_aMXda7EfQdjZjqAA3DNqt","timestamp":1626696451891}],"collapsed_sections":[],"mount_file_id":"1gNh-HsjMOM_aMXda7EfQdjZjqAA3DNqt","authorship_tag":"ABX9TyMrZ7iYALM+6DC5IgUcY/Ya"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"KJT5kqyZGe1p"},"source":["# Multi-layer Perceptron (MLP)"]},{"cell_type":"markdown","metadata":{"id":"NzHP2rndF-0G"},"source":["## 외부 파일 가져오기 & requirements 설치"]},{"cell_type":"code","metadata":{"id":"Mi95dewjGeW_"},"source":["from google.colab import drive\n","drive.mount(\"/content/drive\")\n","import os\n","import sys\n","from datetime import datetime\n","sys.path.append(\"/content/drive/MyDrive/#fastcampus\")\n","!pip install -r \"/content/drive/MyDrive/#fastcampus/requirements.txt\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YD7vyST9GdHv"},"source":["import numpy as np\n","from tqdm import tqdm\n","import matplotlib.pyplot as plt\n","import torch\n","from torch import nn\n","import torch.nn.functional as F\n","from torch import optim\n","from torch.utils.tensorboard import SummaryWriter\n","from torch.utils.data import random_split\n","\n","from torchvision.datasets import FashionMNIST\n","from torchvision import transforms"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QX3soatAMk5B"},"source":["from data_utils import dataset_split"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lISGUqfUG_Ny"},"source":["data_root = os.path.join(os.getcwd(), \"data\")\n","\n","# 전처리 부분 (preprocessing) & 데이터 셋 정의.\n","transform = transforms.Compose(\n","    [\n","        transforms.ToTensor(),\n","        transforms.Normalize([0.5], [0.5]), # mean, # std\n","    ]\n",")\n","fashion_mnist_dataset = FashionMNIST(data_root, download=True, train=True, transform=transform)\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0waoPp23NcE0"},"source":["## Dataloader를 정의"]},{"cell_type":"code","metadata":{"id":"A5Nq1tZiJ84g"},"source":["datasets = dataset_split(fashion_mnist_dataset, split=[0.9, 0.1])\n","\n","train_dataset = datasets[\"train\"]\n","val_dataset = datasets[\"val\"]\n","\n","train_batch_size = 100\n","val_batch_size = 10\n","\n","train_dataloader = torch.utils.data.DataLoader(\n","    train_dataset, batch_size=train_batch_size, shuffle=True, num_workers=1\n",")\n","val_dataloader = torch.utils.data.DataLoader(\n","    val_dataset, batch_size=val_batch_size, shuffle=False, num_workers=1\n",")\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xKRCanL6LtoM"},"source":["for sample_batch in train_dataloader:\n","    print(sample_batch)\n","    print(sample_batch[0].shape, sample_batch[1].shape)\n","    break"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Lwd5nW_3N37z"},"source":["## 모델 (Multi-layer Perceptron) (MLP) ! 정의\n","## 모델 MLPWithDropout 정의\n"]},{"cell_type":"code","metadata":{"id":"-O--VMLMN04F"},"source":["# Define Model.\n","\n","class MLP(nn.Module):\n","    def __init__(self, in_dim: int, h1_dim: int, h2_dim: int, out_dim: int):\n","        super().__init__()\n","        self.linear1 = nn.Linear(in_dim, h1_dim)\n","        self.linear2 = nn.Linear(h1_dim, h2_dim)\n","        self.linear3 = nn.Linear(h2_dim, out_dim)\n","        self.relu = F.relu\n","        pass\n","    \n","    def forward(self, input):\n","        x = torch.flatten(input, start_dim=1)\n","        x = self.relu(self.linear1(x))\n","        x = self.relu(self.linear2(x))\n","        out = self.linear3(x)\n","        # out = F.softmax(out)\n","        return out\n","\n","class MLPWithDropout(MLP):\n","    def __init__(self, in_dim: int, h1_dim: int, h2_dim: int, out_dim: int, dropout_prob: float):\n","        super().__init__(in_dim, h1_dim, h2_dim, out_dim)\n","        self.dropout1 = nn.Dropout(dropout_prob)\n","        self.dropout2 = nn.Dropout(dropout_prob)\n","    \n","    def forward(self, input):\n","        x = torch.flatten(input, start_dim=1)\n","        x = self.relu(self.linear1(x))\n","        x = self.dropout1(x)\n","        x = self.relu(self.linear2(x))\n","        x = self.dropout2(x)\n","        out = self.linear3(x)\n","        # out = F.softmax(out)\n","        return out\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"b8tljBSaQBZB"},"source":["## 모델 선언 및 손실 함수, 최적화(Optimizer) 정의, Tensorboard Logger 정의 "]},{"cell_type":"code","metadata":{"id":"z8p_hsjsO-on"},"source":["# define model.\n","# model = MLP(28*28, 128, 64, 10)\n","model = MLPWithDropout(28*28, 128, 64, 10, dropout_prob=0.3)\n","model_name = type(model).__name__\n","\n","# define loss\n","loss_function = nn.CrossEntropyLoss()\n","\n","# define optimizer\n","optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n","max_epoch = 50\n","\n","# define tensorboard logger\n","log_dir = f\"runs/{datetime.now()}-{model_name}\"\n","writer = SummaryWriter(log_dir=log_dir)\n","log_interval = 100\n","\n","# set save model path\n","log_model_path = os.path.join(log_dir, \"models\")\n","os.makedirs(log_model_path, exist_ok=True)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lnGxA90KyyUi"},"source":["## Early Stopping callback Object Class 정의"]},{"cell_type":"code","metadata":{"id":"WyuzST93ynLE"},"source":["# With some modifications, source is from https://github.com/Bjarten/early-stopping-pytorch\n","\n","class EarlyStopping:\n","    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n","    def __init__(self, patience=7, verbose=False, delta=0, path='checkpoint.ckpt', trace_func=print):\n","        \"\"\"\n","        Args:\n","            patience (int): How long to wait after last time validation loss improved.\n","                            Default: 7\n","            verbose (bool): If True, prints a message for each validation loss improvement. \n","                            Default: False\n","            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n","                            Default: 0\n","            path (str): Path for the checkpoint to be saved to.\n","                            Default: 'checkpoint.ckpt'\n","            trace_func (function): trace print function.\n","                            Default: print            \n","        \"\"\"\n","        self.patience = patience\n","        self.verbose = verbose\n","        self.counter = 0\n","        self.best_score = None\n","        self.early_stop = False\n","        self.val_loss_min = np.Inf\n","        self.delta = delta\n","        self.path = path\n","        self.trace_func = trace_func\n","\n","    def __call__(self, val_loss, model):\n","\n","        score = -val_loss\n","\n","        if self.best_score is None:\n","            self.best_score = score\n","            self.save_checkpoint(val_loss, model)\n","        elif score < self.best_score + self.delta:\n","            self.counter += 1\n","            self.trace_func(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n","            if self.counter >= self.patience:\n","                self.early_stop = True\n","        else:\n","            self.best_score = score\n","            self.save_checkpoint(val_loss, model)\n","            self.counter = 0\n","\n","    def save_checkpoint(self, val_loss, model):\n","        '''Saves model when validation loss decrease.'''\n","        if self.verbose:\n","            self.trace_func(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n","        \n","        filename = self.path.split('/')[-1]\n","        save_dir = os.path.dirname(self.path)\n","        torch.save(model, os.path.join(save_dir, f\"val_loss-{val_loss}-{filename}\"))\n","        self.val_loss_min = val_loss"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oq-XpcGXQu1v"},"source":["%load_ext tensorboard\n","%tensorboard --logdir runs/\n","\n","# define EarlyStopping.\n","early_stopper = EarlyStopping(\n","    patience=3, verbose=True, path=os.path.join(log_model_path, \"model.ckpt\")\n",")\n","\n","# do train with validation.\n","train_step = 0\n","for epoch in range(1, max_epoch+1):\n","    # valid step\n","    with torch.no_grad():\n","        val_loss = 0.0\n","        val_corrects = 0\n","        model.eval()\n","\n","        for val_batch_idx, (val_images, val_labels) in enumerate(\n","            tqdm(val_dataloader, position=0, leave=True, desc=\"validation\")\n","        ):\n","            # forward\n","            val_outputs = model(val_images)\n","            _, val_preds = torch.max(val_outputs, 1)\n","            \n","            # loss & acc\n","            val_loss += loss_function(val_outputs, val_labels) / val_outputs.shape[0]\n","            val_corrects += torch.sum(val_preds == val_labels.data) / val_outputs.shape[0]\n","    \n","    # valid step logging\n","    val_epoch_loss = val_loss / len(val_dataloader)\n","    val_epoch_acc = val_corrects / len(val_dataloader)\n","    \n","    print(\n","        f\"{epoch} epoch, {train_step} step: val_loss: {val_epoch_loss}, val_acc: {val_epoch_acc}\"\n","    )\n","    writer.add_scalar(\"Loss/val\", val_epoch_loss, train_step)\n","    writer.add_scalar(\"Acc/val\", val_epoch_acc, train_step)\n","    writer.add_images(\"Images/val\", val_images, train_step)\n","\n","    # check model early stopping point & save model if the model reached the best performance.\n","    early_stopper(val_epoch_loss, model)\n","    if early_stopper.early_stop:\n","        break\n","    \n","    # train step\n","    current_loss = 0\n","    current_corrects = 0\n","    model.train()\n","\n","    for batch_idx, (images, labels) in enumerate(\n","         tqdm(train_dataloader, position=0, leave=True, desc=\"training\")\n","    ):\n","        current_loss = 0.0\n","        current_corrects = 0\n","\n","        # Forward\n","        # get predictions\n","        outputs = model(images)\n","        _, preds = torch.max(outputs, 1)\n","        \n","        # get loss (Loss 계산)\n","        loss = loss_function(outputs, labels)\n","\n","        # Backpropagation\n","        # optimizer 초기화 (zero화)\n","        optimizer.zero_grad()\n","\n","        # Perform backward pass\n","        loss.backward()\n","\n","        # Perform Optimization\n","        optimizer.step()\n","\n","        current_loss += loss.item()\n","        current_corrects += torch.sum(preds == labels.data)\n","\n","        if train_step % log_interval == 0:\n","            train_loss = current_loss / log_interval\n","            train_acc = current_corrects / log_interval\n","\n","            print(\n","                f\"{train_step}: train_loss: {train_loss}, train_acc: {train_acc}\"\n","            )\n","            writer.add_scalar(\"Loss/train\", train_loss, train_step)\n","            writer.add_scalar(\"Acc/train\", train_acc, train_step)\n","            writer.add_images(\"Images/train\", images, train_step)\n","            writer.add_graph(model, images)\n","            current_loss = 0\n","            current_corrects = 0\n","\n","        train_step += 1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"X1oxnXSyQ2b7"},"source":["# save model\n","# torch.save(model, os.path.join(log_model_path, \"model.ckpt\"))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hipq3Su12nB5"},"source":["log_model_path"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ymnDN1VkYOvt"},"source":["# load model\n","loaded_model = torch.load(os.path.join(log_model_path, \"val_loss-0.03254400193691254-model.ckpt\"))\n","loaded_model.eval()\n","print(loaded_model)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AHvB9xAnYWBk"},"source":["def softmax(x, axis=0):\n","    \"numpy softmax\"\n","    max = np.max(x, axis=axis, keepdims=True)\n","    e_x = np.exp(x - max)\n","    sum = np.sum(e_x, axis=axis, keepdims=True)\n","    f_x = e_x / sum\n","    return f_x"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_UoTf2ztY7nT"},"source":["test_batch_size = 100\n","test_dataset = FashionMNIST(data_root, download=True, train=False, transform=transforms.ToTensor())\n","test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=test_batch_size, shuffle=False, num_workers=1)\n","\n","test_labels_list = []\n","test_preds_list = []\n","test_outputs_list = []\n","for i, (test_images, test_labels) in enumerate(tqdm(test_dataloader, position=0, leave=True, desc=\"testing\")):\n","    # forward\n","    test_outputs = loaded_model(test_images)\n","    _, test_preds = torch.max(test_outputs, 1)\n","\n","    final_outs = softmax(test_outputs.detach().numpy(), axis=1)\n","    test_outputs_list.extend(final_outs)\n","    test_preds_list.extend(test_preds.detach().numpy())\n","    test_labels_list.extend(test_labels.detach().numpy())\n","\n","test_preds_list = np.array(test_preds_list)\n","test_labels_list = np.array(test_labels_list)\n","\n","print(f\"\\nacc: {np.mean(test_preds_list == test_labels_list)*100}%\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"M0a4PPefaRfH"},"source":["# ROC Curve\n","from sklearn.metrics import roc_curve\n","from sklearn.metrics import roc_auc_score\n","\n","fpr = {}\n","tpr = {}\n","thresh = {}\n","n_class = 10\n","\n","for i in range(n_class):\n","    fpr[i], tpr[i], thresh[i] = roc_curve(test_labels_list, np.array(test_outputs_list)[:, i], pos_label=i)\n","\n","# plot.\n","for i in range(n_class):\n","    plt.plot(fpr[i], tpr[i], linestyle=\"--\", label=f\"Class {i} vs Rest\")\n","plt.title(\"Multi-class ROC Curve\")\n","plt.xlabel(\"False Positive Rate\")\n","plt.ylabel(\"True Positive Rate\")\n","plt.legend(loc=\"best\")\n","plt.show()\n","\n","print(\"auc_score\", roc_auc_score(test_labels_list, test_outputs_list, multi_class=\"ovo\", average=\"macro\"))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Dm5jZ7urbMAO"},"source":[""],"execution_count":null,"outputs":[]}]}